{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D,DepthwiseConv2D,ReLU,add\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "import numpy as np\n",
    "import wandb\n",
    "import pathlib\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
    "from wandb.keras import WandbCallback\n",
    "from tensorflow.keras import backend as K\n",
    "import random\n",
    "import math\n",
    "import PIL\n",
    "import glob\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb init\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config={\n",
    "    \"name\":\"SRHW_Sweep\",\n",
    "    \"method\":\"random\",\n",
    "    \"metric\":{\n",
    "        \"name\":\"val_loss\",\n",
    "        \"goal\":\"minimize\"\n",
    "    },\n",
    "    \"parameters\":{\n",
    "        \"learning_rate\":{\n",
    "            \"values\":[0.0001,0.00015,0.0002]\n",
    "        },\n",
    "        \"batch_size\":{\n",
    "            \"values\":[1,2,4,8]\n",
    "        },\n",
    "        \"epochs\":{\n",
    "            \"value\":5000\n",
    "        },\n",
    "        \"optimizer\":{\n",
    "            \"value\":\"adam\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "sweep_id=wandb.sweep(sweep_config,entity=\"krislara\",project=\"SRHW_TensorflowV1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading - load and convert to yuv extract y, normalize for Y and X\n",
    "def preprocess_input(inp,input_size,upscale):\n",
    "    inp=tf.image.rgb_to_yuv(inp)\n",
    "    last_dim=len(inp.shape)-1\n",
    "    y,u,v=tf.split(inp,3,axis=last_dim)\n",
    "    y=tf.image.resize(y,(input_size//upscale,input_size//upscale),method='bicubic')\n",
    "    return y\n",
    "\n",
    "def preprocess_target(inp):\n",
    "    inp=tf.image.rgb_to_yuv(inp)\n",
    "    last_dim=len(inp.shape)-1\n",
    "    y,u,v=tf.split(inp,3,axis=last_dim)\n",
    "    return y\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def data_from_file(file_path):\n",
    "    img=tf.io.read_file(file_path)\n",
    "    img=tf.io.decode_image(img,3,dtype=tf.dtypes.float32,expand_animations=False)\n",
    "    return img\n",
    "    \n",
    "def get_data(data_dir,batch_size=2,img_size=128,upscale=2,shuffle=True):\n",
    "    data_path=tf.data.Dataset.list_files(data_dir,shuffle=shuffle)\n",
    "    data=data_path.map(lambda x:data_from_file(x))    \n",
    "    data=data.batch(batch_size)\n",
    "    data=data.map(lambda x:(preprocess_input(x,input_size=img_size,upscale=upscale),preprocess_target(x)))\n",
    "    data=data.prefetch(buffer_size=AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functional model\n",
    "def get_model(upscale=2,quant=True):\n",
    "    inputs=tf.keras.Input(shape=(None,None,1),name='LR')\n",
    "    x=Conv2D(32,(3,3),padding=\"same\",\n",
    "             use_bias=False,\n",
    "            # data_format='channels_first',\n",
    "             kernel_initializer=RandomUniform(minval=-0.5, maxval=0.5, seed=None)\n",
    "            )(inputs)\n",
    "    x=ReLU(trainable=False)(x)\n",
    "    res=DepthwiseConv2D((1,5),padding='same',\n",
    "                        #data_format='channels_first',\n",
    "                        use_bias=False,\n",
    "                        depthwise_initializer=RandomUniform(minval=-0.5, maxval=0.5, seed=None)\n",
    "                       )(x)\n",
    "    res=Conv2D(16,(1,1),use_bias=False,padding='same',\n",
    "               #data_format='channels_first',\n",
    "               kernel_initializer=RandomUniform(minval=-0.5, maxval=0.5, seed=None)\n",
    "              )(res)\n",
    "    res=ReLU(trainable=False)(res)\n",
    "    res=DepthwiseConv2D((1,5),padding='same',\n",
    "                        #data_format='channels_first',\n",
    "                        use_bias=False,\n",
    "                        depthwise_initializer=RandomUniform(minval=-0.5, maxval=0.5, seed=None)\n",
    "                       )(res)\n",
    "    res=Conv2D(32,1,use_bias=False,padding='same',\n",
    "               #data_format='channels_first',\n",
    "               kernel_initializer=RandomUniform(minval=-0.5, maxval=0.5, seed=None)\n",
    "              )(res)\n",
    "    res=ReLU(trainable=False)(res)\n",
    "    x=add([x,res])\n",
    "\n",
    "    x=DepthwiseConv2D(3,padding='same',\n",
    "                      #data_format='channels_first',\n",
    "                      use_bias=False,\n",
    "                      depthwise_initializer=RandomUniform(minval=-0.5, maxval=0.5, seed=None)\n",
    "                     )(x)\n",
    "    x=Conv2D(16,1,use_bias=False,padding='same',\n",
    "             #data_format='channels_first',\n",
    "             kernel_initializer=RandomUniform(minval=-0.5, maxval=0.5, seed=None)\n",
    "            )(x)\n",
    "    x=ReLU(trainable=False)(x)\n",
    "    x=DepthwiseConv2D(3,padding='same',\n",
    "                      #data_format='channels_first',\n",
    "                      use_bias=False,\n",
    "                    depthwise_initializer=RandomUniform(minval=-0.5, maxval=0.5, seed=None)\n",
    "                     )(x)\n",
    "    x=Conv2D(upscale**2,1,use_bias=False,padding='same',\n",
    "                           #data_format='channels_first',\n",
    "                           kernel_initializer=RandomUniform(minval=-0.5, maxval=0.5, seed=None)\n",
    "            )(x)\n",
    "    ps=tf.nn.depth_to_space(x,upscale,data_format='NHWC',name='HR')\n",
    "    model=None\n",
    "    if quant:\n",
    "        model=tf.keras.Model(inputs=inputs,outputs=x)\n",
    "    else:\n",
    "        model=tf.keras.Model(inputs=inputs,outputs=ps)\n",
    "    model.summary()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(y_true, y_pred):\n",
    "    max_pixel = 1.0\n",
    "    return (10.0 * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true),)))) / 2.303\n",
    "\n",
    "def SSIM(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "class PredictionCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,val_dir,image_size,upscale):\n",
    "        super(PredictionCallback,self).__init__()\n",
    "        self.size=image_size\n",
    "        self.upscale=upscale\n",
    "        self.img_files=[f for f in glob.glob(str(val_dir)+\"/*.png\")]\n",
    "        \n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        if (epoch+1)%100 == 0:\n",
    "            img=load_img(self.img_files[math.floor(random.uniform(1,88))])\n",
    "            img=img.resize(\n",
    "            (img.size[0] // self.upscale, img.size[1] // self.upscale),\n",
    "            PIL.Image.BICUBIC,\n",
    "            )\n",
    "            ycbcr = img.convert(\"YCbCr\")\n",
    "            y, cb, cr = ycbcr.split()\n",
    "            y = tf.keras.preprocessing.image.img_to_array(y)\n",
    "            y = y.astype(\"float32\") / 255.0\n",
    "            input = np.expand_dims(y, axis=0)\n",
    "            y_pred=self.model.predict(input)\n",
    "            display(array_to_img(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=pathlib.Path('/workspace/SRDataset/train/HR/')\n",
    "val_dir=pathlib.Path('/workspace/SRDataset/val/HR/')\n",
    "img_size=128\n",
    "upscale=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    #Consolidate all the above functions\n",
    "    config_defaults=dict(\n",
    "    learning_rate=0.0001,\n",
    "    batch_size=4,\n",
    "    epochs=5000,\n",
    "    optimizer='adam',\n",
    "    loss='MAE',\n",
    "    Dataset='SRDataset',\n",
    "    Model='SRHW',\n",
    "    )\n",
    "    wandb.init(config=config_defaults)\n",
    "    config=wandb.config\n",
    "    train_ds=get_data(str(train_dir/'*'),batch_size=config.batch_size,img_size=img_size,upscale=upscale,shuffle=True)\n",
    "    valid_ds=get_data(str(val_dir/'*'),batch_size=88,img_size=img_size*2,upscale=upscale,shuffle=True)\n",
    "    model=get_model(quant=False)\n",
    "    if config.optimizer=='adam':\n",
    "        optimizer=Adam(learning_rate=config.learning_rate,name='Adam',clipnorm=1.0)\n",
    "    elif config.optimizer=='sgd':\n",
    "        optimizer=SGD(learning_rate=config.learning_rate,momentum=0.9,name='SGD',clipnorm=1.0)\n",
    "    model.compile(optimizer,loss=tf.keras.losses.MeanAbsoluteError(),metrics=[PSNR,SSIM])\n",
    "    callbacks=[\n",
    "    WandbCallback(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_weights_only=True,\n",
    "        log_weights=True\n",
    "        ),\n",
    "        PredictionCallback(val_dir,img_size*2,upscale)\n",
    "    ]\n",
    "    model.fit(train_ds,epochs=config.epochs,callbacks=callbacks,validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://keras.io/examples/vision/super_resolution_sub_pixel/\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "\n",
    "model_path='/workspace/SRHW/tf_ckpt/model1.h5'\n",
    "dependencies = {\n",
    "    'PSNR': PSNR,\n",
    "    'SSIM':SSIM\n",
    "}\n",
    "\n",
    "# trained_model=tf.keras.models.load_model(model_path,custom_objects=dependencies)\n",
    "\n",
    "def plot_results(img, prefix, title,area):\n",
    "    \"\"\"Plot the result with zoom-in area.\"\"\"\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = img_array.astype(\"float32\") / 255.0\n",
    "\n",
    "    # Create a new figure with a default 111 subplot.\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(img_array[::-1], origin=\"lower\")\n",
    "\n",
    "    plt.title(title)\n",
    "#     # zoom-factor: 2.0, location: upper-left\n",
    "#     axins = zoomed_inset_axes(ax, 2, loc=2)\n",
    "#     axins.imshow(img_array[::-1], origin=\"lower\")\n",
    "\n",
    "#     # Specify the limits.\n",
    "#     x1, x2, y1, y2 = area\n",
    "#     # Apply the x-limits.\n",
    "#     axins.set_xlim(x1, x2)\n",
    "#     # Apply the y-limits.\n",
    "#     axins.set_ylim(y1, y2)\n",
    "\n",
    "#     plt.yticks(visible=False)\n",
    "#     plt.xticks(visible=False)\n",
    "\n",
    "#     # Make the line.\n",
    "#     mark_inset(ax, axins, loc1=1, loc2=3, fc=\"none\", ec=\"blue\")\n",
    "#     plt.savefig(str(prefix) + \"-\" + title + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "def get_lowres_image(img, upscale_factor):\n",
    "    \"\"\"Return low-resolution image to use as model input.\"\"\"\n",
    "    return img.resize(\n",
    "        (img.size[0] // upscale_factor, img.size[1] // upscale_factor),\n",
    "        PIL.Image.BICUBIC,\n",
    "    )\n",
    "    \n",
    "\n",
    "def upscale_image(model, img):\n",
    "    \"\"\"Predict the result based on input image and restore the image as RGB.\"\"\"\n",
    "    ycbcr = img.convert(\"YCbCr\")\n",
    "    y, cb, cr = ycbcr.split()\n",
    "    y = tf.keras.preprocessing.image.img_to_array(y)\n",
    "    y = y.astype(\"float32\") / 255.0\n",
    "\n",
    "    input = np.expand_dims(y, axis=0)\n",
    "#     input= np.transpose(input,[0,3,1,2])\n",
    "    out = model.predict(input)\n",
    "    \n",
    "#     out_img_y =np.transpose(out,[0,2,3,1])\n",
    "    out_img_y = out[0]\n",
    "#     out_img_y =np.transpose(out_img_y,[1,2,0])\n",
    "    out_img_y *= 255.0\n",
    "    \n",
    "\n",
    "    # Restore the image in RGB color space.\n",
    "    out_img_y = out_img_y.clip(0, 255)\n",
    "    out_img_y = out_img_y.reshape((np.shape(out_img_y)[0], np.shape(out_img_y)[1]))\n",
    "    out_img_y = PIL.Image.fromarray(np.uint8(out_img_y), mode=\"L\")\n",
    "    out_img_cb = cb.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img_cr = cr.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img = PIL.Image.merge(\"YCbCr\", (out_img_y, out_img_cb, out_img_cr)).convert(\n",
    "        \"RGB\"\n",
    "    )\n",
    "    return out_img\n",
    "\n",
    "img_files=[f for f in glob.glob(str(val_dir)+\"/*.png\")]\n",
    "img=tf.keras.preprocessing.image.load_img(img_files[math.floor(random.uniform(1,88))])\n",
    "lr=get_lowres_image(img,2)\n",
    "w,h=lr.size[0]*2,lr.size[1]*2\n",
    "hr=img.resize((w,h))\n",
    "sr=upscale_image(model,lr)\n",
    "plot_results(lr,0, \"lowres\",(32, 96, 32, 96))\n",
    "plot_results(hr, 0, \"highres\",(96, 160, 96, 160))\n",
    "plot_results(sr, 0, \"superres\",(96, 160, 96, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dugout\n",
    "# metrics for compile\n",
    "# class PSNR(tf.keras.metrics.Metric):\n",
    "#     def __init__(self,name='PSNR',**kwargs):\n",
    "#         super(PSNR,self).__init__(name=name,**kwargs)\n",
    "#         self.psnr=self.add_weight(name='PSNR', initializer='zeros')\n",
    "    \n",
    "#     def update_state(self,y_true,y_pred,sample_weight=None):\n",
    "#         self.psnr.assign_add=tf.image.psnr(y_true,y_pred,max_val=1.0)\n",
    "    \n",
    "#     def result(self):\n",
    "#         return self.psnr\n",
    "\n",
    "# class SSIM(tf.keras.metrics.Metric):\n",
    "#     def __init__(self,name='SSIM',**kwargs):\n",
    "#         super(SSIM,self).__init__(name=name,**kwargs)\n",
    "#         self.ssim=self.add_weight(name='SSIM',initializer='zeros')\n",
    "    \n",
    "#     def update_state(self,y_true,y_pred,sample_weight=None):\n",
    "#         self.ssim.assign_add=tf.image.ssim(y_true,y_pred,max_val=1.0)\n",
    "    \n",
    "#     def result(self):\n",
    "#         return self.ssim\n",
    "\n",
    "\n",
    "# def create_model(input_dims,upscale,quant):\n",
    "#     dim1,dim2= input_dims[1]//upscale,input_dims[2]//upscale \n",
    "#     model = SRHW((1,dim1,dim2),upscale=upscale,quant=quant)\n",
    "#     model.build((None,1,dim1,dim2))\n",
    "#     model.build_graph().summary()\n",
    "#     tf.keras.utils.plot_model(\n",
    "#         model.build_graph(), to_file='model.png', show_shapes=True, show_layer_names=True,\n",
    "#         rankdir='TB', expand_nested=False, dpi=96\n",
    "#     )\n",
    "#     return model\n",
    "\n",
    "\n",
    "# Model subclassing\n",
    "# class SRHW(tf.keras.Model):\n",
    "#     def __init__(self,upscale=2,quant=False,dim=(1,64,64)):\n",
    "#         super(SRHW,self).__init__()\n",
    "#         self.Conv1=Conv2D(32,3,padding=\"same\",\n",
    "#                           use_bias=False,data_format='channels_first',\n",
    "#                           kernel_initializer=RandomUniform(minval=-0.05, maxval=0.05, seed=None))\n",
    "#         self.DWConv1=DepthwiseConv2D((1,5),padding='same',\n",
    "#                                     data_format='channels_first',use_bias=False,\n",
    "#                                     depthwise_initializer=RandomUniform(minval=-0.05, maxval=0.05, seed=None))\n",
    "#         self.PWConv1=Conv2D(16,1,use_bias=False,padding='same',\n",
    "#                            data_format='channels_first',\n",
    "#                            kernel_initializer=RandomUniform(minval=-0.05, maxval=0.05, seed=None))\n",
    "#         self.DWConv2=DepthwiseConv2D((1,5),padding='same',\n",
    "#                                     data_format='channels_first',use_bias=False,\n",
    "#                                     depthwise_initializer=RandomUniform(minval=-0.05, maxval=0.05, seed=None))\n",
    "#         self.PWConv2=Conv2D(32,1,use_bias=False,padding='same',\n",
    "#                            data_format='channels_first',\n",
    "#                            kernel_initializer=RandomUniform(minval=-0.05, maxval=0.05, seed=None))\n",
    "#         self.DWConv3=DepthwiseConv2D(3,padding='same',\n",
    "#                                     data_format='channels_first',use_bias=False,\n",
    "#                                     depthwise_initializer=RandomUniform(minval=-0.05, maxval=0.05, seed=None))\n",
    "#         self.PWConv3=Conv2D(16,1,use_bias=False,padding='same',\n",
    "#                            data_format='channels_first',\n",
    "#                            kernel_initializer=RandomUniform(minval=-0.05, maxval=0.05, seed=None))\n",
    "#         self.DWConv4=DepthwiseConv2D(3,padding='same',\n",
    "#                                     data_format='channels_first',use_bias=False,\n",
    "#                                     depthwise_initializer=RandomUniform(minval=-0.05, maxval=0.05, seed=None))\n",
    "#         self.PWConv4=Conv2D(upscale**2,1,use_bias=False,padding='same',\n",
    "#                            data_format='channels_first',\n",
    "#                            kernel_initializer=RandomUniform(minval=-0.05, maxval=0.05, seed=None))\n",
    "#         self.upscale=upscale\n",
    "#         self.relu1=ReLU()\n",
    "#         self.relu2=ReLU()\n",
    "#         self.relu3=ReLU()\n",
    "#         self.relu4=ReLU()\n",
    "#         self.quant=quant\n",
    "#         self.dim=dim\n",
    "        \n",
    "#     def call(self,x):\n",
    "#         x=self.Conv1(x)\n",
    "#         res=self.relu1(x)\n",
    "#         res=self.DWConv1(res)\n",
    "#         res=self.PWConv1(res)\n",
    "#         res=self.relu2(res)\n",
    "#         res=self.PWConv2(self.DWConv2(res))\n",
    "#         x=x+res\n",
    "#         x=self.relu3(x)\n",
    "#         x=self.relu4(self.PWConv3(self.DWConv3(x)))\n",
    "#         x=self.PWConv4(self.DWConv4(x))\n",
    "#         if self.quant:\n",
    "#             return x\n",
    "#         else:\n",
    "#             return tf.nn.depth_to_space(x,self.upscale,data_format='NCHW')\n",
    "#     def build_graph(self):\n",
    "#         x = tf.keras.layers.Input(shape=(self.dim))\n",
    "#         return tf.keras.Model(inputs=[x], outputs=self.call(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
